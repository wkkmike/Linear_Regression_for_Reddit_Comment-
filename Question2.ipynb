{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # we need to use the JSON package to load the data, since the data is stored in JSON format\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"proj1_data.json\") as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowers every word's text, and split\n",
    "for data_point in data:\n",
    "    data_point[\"text\"] = data_point[\"text\"].lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets Traning, Validation, Test sets\n",
    "training_sets = data[:10000]\n",
    "validation_sets = data[10000:11000]\n",
    "test_sets = data[11000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds words recurring number\n",
    "words_recurrence = {}\n",
    "for data_point in training_sets:\n",
    "    for word in data_point[\"text\"]:\n",
    "        if word in words_recurrence:\n",
    "            words_recurrence[word] += 1\n",
    "        else:\n",
    "            words_recurrence[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorts from high to low amd trim to size 160\n",
    "words_recurrence = sorted(words_recurrence.items(), key=lambda kv: kv[1], reverse=True)\n",
    "del words_recurrence[160:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 160 most frequently occurring words (from 0 to 159)\n",
    "# Builds vector w\n",
    "w = {}\n",
    "i = 0\n",
    "for word in words_recurrence:\n",
    "    w[word[0]] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds matrix x\n",
    "x = np.zeros((10000, 160))\n",
    "i = 0\n",
    "for data_point in training_sets:\n",
    "    for word in data_point[\"text\"]:\n",
    "        if word in w:\n",
    "            x[i, w[word]] += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds vector y\n",
    "y = np.zeros(12000)\n",
    "i = 0\n",
    "for data_point in data:\n",
    "    y[i] = data_point[\"popularity_score\"]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits y into Traning, Validation, Test vectors\n",
    "y_training = y[:10000]\n",
    "y_validation = y[10000:11000]\n",
    "y_test = y[11000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closed-form solution\n",
    "weight_closed = np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(x), x)), np.transpose(x)), y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
